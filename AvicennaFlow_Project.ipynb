{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t2ScEeogWOm7"
   },
   "source": [
    "# 🧠 AvicennaFlow Project\n",
    "\n",
    "**Title**: *Biologically Plausible Learning in CNNs: A Comparison of Backpropagation, DFA, and DKP for Image Classification*   \n",
    "**Inspiration**: Inspired by Avicenna (Ibn Sina), this project explores the intersection of neuroscience and AI through biologically plausible learning algorithms.\n",
    "\n",
    "\n",
    "\n",
    "## 📌 Project Motivation\n",
    "\n",
    "This project investigates how biologically plausible alternatives to backpropagation—namely **Direct Feedback Alignment (DFA)** and **Direct Kolen–Pollack (DKP)**—perform in image classification tasks.\n",
    "\n",
    "**Key questions include:**\n",
    "- How do bio-inspired algorithms compare to backpropagation in classification accuracy?\n",
    "- How do their learning dynamics and generalization capabilities differ?\n",
    "- How robust are these algorithms against adversarial attacks?\n",
    "- What insights can we gain from their bias–variance profiles?\n",
    "\n",
    "**Datasets used**:\n",
    "- MNIST\n",
    "- CIFAR-10\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📦 Dependency Installation (Colab Only)\n",
    "\n",
    "Install core packages like `torch`, `torchvision`, `rsatoolbox`, and `vibecheck`.  \n",
    "> ⚠️ *Note: These are only required when running the notebook in Google Colab.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P6S2N1IvWNOq",
    "outputId": "18274814-c46e-42f9-f047-aec3e87ac68b"
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision matplotlib numpy scikit-learn scipy vibecheck --quiet\n",
    "!pip install rsatoolbox==0.1.5 --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧰 Library Imports\n",
    "\n",
    "Import all required Python libraries for:\n",
    "- Deep learning (`torch`, `torchvision`)\n",
    "- Analysis (`rsatoolbox`, `sklearn`, `scipy`)\n",
    "- Plotting (`matplotlib`, `seaborn`)\n",
    "- Utility and logging (`argparse`, `numpy`, `contextlib`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import logging\n",
    "import contextlib\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "from types import SimpleNamespace\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "# External libraries: General utilities\n",
    "import argparse\n",
    "\n",
    "# NumPy\n",
    "import numpy as np\n",
    "from numpy import prod\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# TorchVision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models.feature_extraction import (\n",
    "    create_feature_extractor, get_graph_node_names\n",
    ")\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "# Matplotlib for plotting\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline  # Only needed in Jupyter notebooks\n",
    "\n",
    "# SciPy for statistical functions\n",
    "import scipy\n",
    "from scipy import stats\n",
    "\n",
    "# Scikit-Learn for machine learning utilities\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import manifold\n",
    "\n",
    "# RSA toolbox imports\n",
    "import rsatoolbox\n",
    "from rsatoolbox.data import Dataset\n",
    "from rsatoolbox.rdm.calc import calc_rdm\n",
    "import rsatoolbox.rdm\n",
    "from rsatoolbox.rdm import RDMs\n",
    "\n",
    "# Warnings settings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎨 Plot Configuration\n",
    "\n",
    "We configure plotting aesthetics and fonts using Neuromatch Academy style.  \n",
    "This ensures high-resolution, consistent visuals across platforms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "JkTUu2eAZTyI"
   },
   "outputs": [],
   "source": [
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina' # perfrom high definition rendering for images and plots\n",
    "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/nma.mplstyle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚙️ Configuration Parameters\n",
    "\n",
    "All experiment settings are defined here, including:\n",
    "- Dataset choice (`MNIST` or `CIFAR10`)\n",
    "- Learning rates for each method\n",
    "- Model name, batch size, device, epoch count\n",
    "- Seed value and checkpoint paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "08l5PkJNZzc7"
   },
   "outputs": [],
   "source": [
    "args = SimpleNamespace(\n",
    "    train_mode='',\n",
    "    dataset='',\n",
    "    epochs=5,\n",
    "    batch_size=64,\n",
    "    test_batch_size=1000,\n",
    "    bp_lr=1,\n",
    "    lr=5e-4,\n",
    "    b_lr=1e-4,\n",
    "    gamma=0.8,\n",
    "    no_cuda=False,\n",
    "    dry_run=False,\n",
    "    seed=42,\n",
    "    log_interval=10,\n",
    "    save_model=True,\n",
    ")\n",
    "\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "args.device = device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔁 Reproducibility\n",
    "\n",
    "We define a function to fix the random seed in Python, NumPy, and PyTorch  \n",
    "for consistent and reproducible training results across runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "j8M4xowRZds6"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def set_seed(seed=None, seed_torch=True):\n",
    "  if seed is None:\n",
    "    seed = np.random.choice(2 ** 32)\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  if seed_torch:\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(seed = args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧰 Utility Functions\n",
    "\n",
    "This block defines helper functions for:\n",
    "- Data loading and preprocessing\n",
    "- Feature extraction using forward and backward hooks\n",
    "- Adversarial image generation (FGSM)\n",
    "- Logging metrics into CSV format\n",
    "- Visualization and sampling utilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "def calc_rdms(model_features, method='correlation'):\n",
    "    \"\"\"\n",
    "    Calculates representational dissimilarity matrices (RDMs) for model features.\n",
    "\n",
    "    Inputs:\n",
    "    - model_features (dict): A dictionary where keys are layer names and values are features of the layers.\n",
    "    - method (str): The method to calculate RDMs, e.g., 'correlation'. Default is 'correlation'.\n",
    "\n",
    "    Outputs:\n",
    "    - rdms (pyrsa.rdm.RDMs): RDMs object containing dissimilarity matrices.\n",
    "    - rdms_dict (dict): A dictionary with layer names as keys and their corresponding RDMs as values.\n",
    "    \"\"\"\n",
    "    ds_list = []\n",
    "    for l in range(len(model_features)):\n",
    "        layer = list(model_features.keys())[l]\n",
    "        feats = model_features[layer]\n",
    "\n",
    "        if type(feats) is list:\n",
    "            feats = feats[-1]\n",
    "\n",
    "        if not args.no_cuda:\n",
    "            feats = feats.cpu()\n",
    "\n",
    "        if len(feats.shape) > 2:\n",
    "            feats = feats.flatten(1)\n",
    "\n",
    "        feats = feats.detach().numpy()\n",
    "        ds = Dataset(feats, descriptors=dict(layer=layer))\n",
    "        ds_list.append(ds)\n",
    "\n",
    "    rdms = calc_rdm(ds_list, method=method)\n",
    "    rdms_dict = {list(model_features.keys())[i]: rdms.get_matrices()[i] for i in range(len(model_features))}\n",
    "\n",
    "    return rdms, rdms_dict\n",
    "\n",
    "def fetch_dataloaders(args):\n",
    "    \"\"\"\n",
    "    Fetches the data loaders for training and testing datasets.\n",
    "\n",
    "    Inputs:\n",
    "    - args (Namespace): Parsed arguments with training configuration.\n",
    "\n",
    "    Outputs:\n",
    "    - train_loader (torch.utils.data.DataLoader): DataLoader for the training data.\n",
    "    - test_loader (torch.utils.data.DataLoader): DataLoader for the test data.\n",
    "    \"\"\"\n",
    "    train_kwargs = {'batch_size': args.batch_size}\n",
    "    test_kwargs = {'batch_size': args.test_batch_size}\n",
    "    if not args.no_cuda:\n",
    "        cuda_kwargs = {'num_workers': 1,\n",
    "                       'pin_memory': True,\n",
    "                       'shuffle': True}\n",
    "        train_kwargs.update(cuda_kwargs)\n",
    "        test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "    if args.dataset == 'CIFAR10':\n",
    "\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "        with contextlib.redirect_stdout(io.StringIO()): #to suppress output\n",
    "            train_data = datasets.CIFAR10(root='~/data', train=True, download=True, transform=transform)\n",
    "            train_loader = torch.utils.data.DataLoader(train_data, **train_kwargs)\n",
    "\n",
    "            test_data = datasets.CIFAR10(root='~/data', train=False, download=True, transform=transform)\n",
    "            test_loader = torch.utils.data.DataLoader(test_data, **test_kwargs)\n",
    "\n",
    "    elif args.dataset == 'MNIST':\n",
    "\n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ])\n",
    "        with contextlib.redirect_stdout(io.StringIO()): #to suppress output\n",
    "            dataset1 = datasets.MNIST('~/data', train=True, download=True, transform=transform)\n",
    "            dataset2 = datasets.MNIST('~/data', train=False, download=True, transform=transform)\n",
    "\n",
    "            train_loader = torch.utils.data.DataLoader(dataset1, **train_kwargs)\n",
    "            test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "def sample_images_cifar(data_loader, n=5, plot=False, unnormalize=True):\n",
    "    \"\"\"\n",
    "    Return ≤ n images per class from a DataLoader (first batch only)\n",
    "    and, optionally, display them.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    data_loader : torch.utils.data.DataLoader\n",
    "    n           : images per class (default 5)\n",
    "    plot        : show a grid with matplotlib (default False)\n",
    "    unnormalize : map images back to [0,1] if they were normalized (default True)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    imgs   : torch.Tensor  # shape (k, C, H, W)\n",
    "    labels : torch.Tensor  # shape (k,)\n",
    "    \"\"\"\n",
    "    # pull one batch\n",
    "    imgs, targets = next(iter(data_loader))\n",
    "\n",
    "    # find unique class labels in that batch\n",
    "    classes = torch.unique(targets)\n",
    "\n",
    "    imgs_out, lbls_out = [], []\n",
    "    for c in classes:\n",
    "        idx = torch.where(targets == c)[0][:n]       # first n of that class\n",
    "        imgs_out.append(imgs[idx])\n",
    "        lbls_out.extend([c.item()] * len(idx))\n",
    "\n",
    "    imgs_out = torch.cat(imgs_out, dim=0)\n",
    "    labels   = torch.tensor(lbls_out)\n",
    "\n",
    "    if unnormalize:\n",
    "        # reverse the common CIFAR‑10 normalisation (mean=std=0.5)\n",
    "        imgs_plot = imgs_out * 0.5 + 0.5             # -> [0,1]\n",
    "    else:\n",
    "        imgs_plot = imgs_out\n",
    "\n",
    "    if plot:\n",
    "        with plt.xkcd():\n",
    "            grid = make_grid(imgs_plot, nrow=5, padding=0)\n",
    "            plt.imshow(grid.permute(1, 2, 0).cpu())  # (C,H,W) -> (H,W,C)\n",
    "            plt.axis(\"off\")\n",
    "            plt.show()\n",
    "\n",
    "    return imgs_out, labels\n",
    "\n",
    "def sample_images_mnist(data_loader, n=5, plot=False):\n",
    "    \"\"\"\n",
    "    Samples a specified number of images from a data loader.\n",
    "\n",
    "    Inputs:\n",
    "    - data_loader (torch.utils.data.DataLoader): Data loader containing images and labels.\n",
    "    - n (int): Number of images to sample per class.\n",
    "    - plot (bool): Whether to plot the sampled images using matplotlib.\n",
    "\n",
    "    Outputs:\n",
    "    - imgs (torch.Tensor): Sampled images.\n",
    "    - labels (torch.Tensor): Corresponding labels for the sampled images.\n",
    "    \"\"\"\n",
    "\n",
    "    with plt.xkcd():\n",
    "        imgs, targets = next(iter(data_loader))\n",
    "\n",
    "        imgs_o = []\n",
    "        labels = []\n",
    "        for value in range(10):\n",
    "            cat_imgs = imgs[np.where(targets == value)][0:n]\n",
    "            imgs_o.append(cat_imgs)\n",
    "            labels.append([value]*len(cat_imgs))\n",
    "\n",
    "        imgs = torch.cat(imgs_o, dim=0)\n",
    "        labels = torch.tensor(labels).flatten()\n",
    "\n",
    "        if plot:\n",
    "            plt.imshow(torch.moveaxis(make_grid(imgs, nrow=5, padding=0, normalize=False, pad_value=0), 0,-1))\n",
    "            plt.axis('off')\n",
    "\n",
    "        return imgs, labels\n",
    "\n",
    "def extract_features_dkp(model, imgs):\n",
    "    \"\"\"\n",
    "    Extracts features from specified layers of the model.\n",
    "\n",
    "    Inputs:\n",
    "    - model (torch.nn.Module): The model from which to extract features.\n",
    "    - imgs (torch.Tensor): Batch of input images.\n",
    "\n",
    "    Outputs:\n",
    "    - model_features (dict): A dictionary with layer names as keys and extracted features as values.\n",
    "                              Also includes 'input' key for the input images.\n",
    "    \"\"\"\n",
    "    model_features = {}\n",
    "\n",
    "    def save_features(name):\n",
    "        def hook(module, input, output):\n",
    "            model_features[name] = output.detach().cpu()\n",
    "        return hook\n",
    "\n",
    "    # Register hooks for conv and linear layers\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "            module.register_forward_hook(save_features(name))\n",
    "\n",
    "    # Also store input images\n",
    "    model_features['input'] = imgs.detach().cpu()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        _ = model(imgs)\n",
    "\n",
    "    # convert fc2 logits to probs\n",
    "    logits = model_features['fc2']               # shape [batch_size, 10]\n",
    "    probs  = F.softmax(logits, dim=1)            # now in [0,1], sum to 1 per row\n",
    "    model_features['fc2'] = probs \n",
    "\n",
    "    return model_features\n",
    "\n",
    "def extract_features_bp(model, imgs, return_layers):\n",
    "    \"\"\"\n",
    "    Extracts features from specified layers of the model.\n",
    "\n",
    "    Inputs:\n",
    "    - model (torch.nn.Module): The model from which to extract features.\n",
    "    - imgs (torch.Tensor): Batch of input images.\n",
    "    - return_layers (list): List of layer names from which to extract features.\n",
    "    - plot (str): Option to plot the features. Default is 'none'.\n",
    "\n",
    "    Outputs:\n",
    "    - model_features (dict): A dictionary with layer names as keys and extracted features as values.\n",
    "    \"\"\"\n",
    "    if return_layers == 'all':\n",
    "        return_layers, _ = get_graph_node_names(model)\n",
    "    elif return_layers == 'layers':\n",
    "        layers, _ = get_graph_node_names(model)\n",
    "        return_layers = [l for l in layers if 'input' in l or 'conv' in l or 'fc' in l]\n",
    "\n",
    "    feature_extractor = create_feature_extractor(model, return_nodes=return_layers)\n",
    "    model_features = feature_extractor(imgs)\n",
    "\n",
    "    # convert fc2 logits to probs\n",
    "    logits = model_features['fc2']               # shape [batch_size, 10]\n",
    "    probs  = F.softmax(logits, dim=1)            # now in [0,1], sum to 1 per row\n",
    "    model_features['fc2'] = probs \n",
    "\n",
    "    return model_features\n",
    "\n",
    "def fgsm_attack(image, epsilon, data_grad):\n",
    "    \"\"\"\n",
    "    Performs FGSM attack on an image.\n",
    "\n",
    "    Inputs:\n",
    "    - image (torch.Tensor): Original image.\n",
    "    - epsilon (float): Perturbation magnitude.\n",
    "    - data_grad (torch.Tensor): Gradient of the data.\n",
    "\n",
    "    Outputs:\n",
    "    - perturbed_image (torch.Tensor): Perturbed image after FGSM attack.\n",
    "    \"\"\"\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    perturbed_image = image + epsilon * sign_data_grad\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    return perturbed_image\n",
    "\n",
    "def denorm(batch, mean, std):\n",
    "    mean = torch.tensor(mean, device=batch.device)\n",
    "    std = torch.tensor(std, device=batch.device)\n",
    "    return batch * std.view(1, -1, 1, 1) + mean.view(1, -1, 1, 1)\n",
    "\n",
    "def normalize(batch, mean, std):\n",
    "    mean = torch.tensor(mean, device=batch.device)\n",
    "    std = torch.tensor(std, device=batch.device)\n",
    "    return (batch - mean.view(1, -1, 1, 1)) / std.view(1, -1, 1, 1)\n",
    "\n",
    "def generate_adversarial(args, model, imgs, targets):\n",
    "    \"\"\"\n",
    "    Generates adversarial examples using FGSM attack for MNIST or CIFAR-10.\n",
    "\n",
    "    Inputs:\n",
    "    - model (torch.nn.Module): The model to attack.\n",
    "    - imgs (torch.Tensor): Batch of normalized images.\n",
    "    - targets (torch.Tensor): Batch of target labels.\n",
    "\n",
    "    Outputs:\n",
    "    - adv_imgs (torch.Tensor): Batch of adversarial images (normalized).\n",
    "    \"\"\"\n",
    "    if args.dataset == 'MNIST':\n",
    "        mean = [0.1307]\n",
    "        std = [0.3081]\n",
    "        epsilon = 0.2\n",
    "    elif args.dataset == 'CIFAR10':\n",
    "        mean = [0.5, 0.5, 0.5]\n",
    "        std = [0.5, 0.5, 0.5]\n",
    "        epsilon = 0.03\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported dataset: {args.dataset}\")\n",
    "\n",
    "    adv_imgs = []\n",
    "\n",
    "    for img, target in zip(imgs, targets):\n",
    "        img = img.unsqueeze(0)\n",
    "        target = target.unsqueeze(0)\n",
    "        img.requires_grad = True\n",
    "\n",
    "        output = model(img)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        data_grad = img.grad.data\n",
    "        data_denorm = denorm(img, mean, std)\n",
    "        perturbed_data = fgsm_attack(data_denorm, epsilon, data_grad)\n",
    "        perturbed_data_normalized = normalize(perturbed_data, mean, std)\n",
    "\n",
    "        adv_imgs.append(perturbed_data_normalized.detach())\n",
    "\n",
    "    return torch.cat(adv_imgs)\n",
    "\n",
    "def test_adversarial(model, imgs, targets):\n",
    "    \"\"\"\n",
    "    Tests the model on adversarial examples and prints the accuracy.\n",
    "\n",
    "    Inputs:\n",
    "    - model (torch.nn.Module): The model to be tested.\n",
    "    - imgs (torch.Tensor): Batch of adversarial images.\n",
    "    - targets (torch.Tensor): Batch of target labels.\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    model.eval()\n",
    "    output = model(imgs)\n",
    "    pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "    correct += pred.eq(targets.view_as(pred)).sum().item()\n",
    "\n",
    "    final_acc = correct / float(len(imgs))\n",
    "    # print(f\"adversarial test accuracy = {correct} / {len(imgs)} = {final_acc}\")\n",
    "    return final_acc\n",
    "\n",
    "class CSVLogger:\n",
    "    def __init__(self, fieldnames, args):\n",
    "        datetime = time.strftime('%y%m%d_%H%M%S')\n",
    "        self.fieldnames = fieldnames\n",
    "\n",
    "        filedir = os.path.relpath(os.path.join('results', args.train_mode))\n",
    "        if not os.path.exists(filedir):\n",
    "            os.makedirs(filedir)\n",
    "        self.filename = os.path.relpath(os.path.join(filedir, f\"{args.train_mode.lower()}_{args.dataset.lower()}_epochs{args.epochs}_{datetime}.csv\"))\n",
    "\n",
    "        with open(self.filename, 'a', newline='') as csvfile:\n",
    "            csvfile.write(str(args) + '\\n')\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=self.fieldnames)\n",
    "            writer.writeheader()\n",
    "\n",
    "    def save_values(self, *values):\n",
    "        assert len(values) == len(self.fieldnames), 'The number of values should match the number of field names.'\n",
    "        with open(self.filename, 'a', newline='') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=self.fieldnames)\n",
    "            row = {}\n",
    "            for i, val in enumerate(values):\n",
    "                row[self.fieldnames[i]] = val\n",
    "\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧠 Representational Similarity Analysis (RSA)\n",
    "\n",
    "We extract intermediate layer activations and compute RDMs  \n",
    "to evaluate how similarly models represent input images internally.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_names = ['BP', 'DKP', 'DFA']\n",
    "model_colors = {'BP': 'blue', 'DKP': 'green', 'DFA': 'red'}\n",
    "\n",
    "def load_models(args, imgs):\n",
    "    \n",
    "    batch_size = imgs.shape[0]\n",
    "    in_channels = imgs.shape[1]\n",
    "    input_height = imgs.shape[2]\n",
    "    \n",
    "    # ----- BP -----\n",
    "    model_bp = ConvNetBP(in_channels, input_height)\n",
    "    model_bp.load_state_dict(torch.load(f\"model_checkpoints/BP_{args.dataset}_epoch5_s{args.seed}.pth\", map_location=args.device))\n",
    "    model_bp.to(args.device)\n",
    "    \n",
    "    # ----- DKP -----\n",
    "    args.train_mode = 'DKP' \n",
    "    model_dkp = ConvNetDKP(args, in_channels, input_height) \n",
    "    model_dkp.to(args.device)\n",
    "    with torch.no_grad():\n",
    "        model_dkp(torch.randn(batch_size, in_channels, input_height, input_height).to(args.device))\n",
    "    model_dkp.load_state_dict(torch.load(f'model_checkpoints/DKP_{args.dataset}_epoch5_s{args.seed}.pt', map_location=args.device), strict=False)\n",
    "    \n",
    "    # ----- DFA -----\n",
    "    args.train_mode = 'DFA' \n",
    "    model_dfa = ConvNetDKP(args, in_channels, input_height)\n",
    "    model_dfa.to(args.device)\n",
    "    with torch.no_grad():\n",
    "        model_dfa(torch.randn(batch_size, in_channels, input_height, input_height).to(args.device))\n",
    "    model_dfa.load_state_dict(torch.load(f'model_checkpoints/DFA_{args.dataset}_epoch5_s{args.seed}.pt', map_location=args.device), strict=False)\n",
    "\n",
    "    models = {'BP': model_bp, 'DKP': model_dkp, 'DFA': model_dfa}\n",
    "    return models\n",
    "\n",
    "def grab_features_and_rdms(args, imgs, labels, rdm_method='correlation', adversarial=False, seed=42):\n",
    "  \n",
    "    models_rdms = []\n",
    "    models_feats = []\n",
    "    adv_accuracies = []\n",
    "\n",
    "    models = load_models(args, imgs)\n",
    "    model_bp = models['BP']\n",
    "    model_dkp = models['DKP']\n",
    "    model_dfa = models['DFA']\n",
    "\n",
    "    imgs = imgs.to(args.device)\n",
    "    labels = labels.to(args.device)\n",
    "    \n",
    "    # ----- BP -----\n",
    "    # model_bp.eval()\n",
    "    if adversarial == True:\n",
    "        imgs = generate_adversarial(args, model_bp, imgs, labels)\n",
    "        adv_acc = test_adversarial(model_bp, imgs, labels)\n",
    "        adv_accuracies.append(adv_acc)\n",
    "    return_layers = ['input', 'conv1', 'conv2', 'fc1', 'fc2']\n",
    "    features_bp = extract_features_bp(model_bp, imgs, return_layers=return_layers)\n",
    "    _, rdms_bp = calc_rdms(features_bp, rdm_method)\n",
    "    models_feats.append(features_bp)\n",
    "    models_rdms.append(rdms_bp)\n",
    "    \n",
    "    # ----- DKP -----\n",
    "    # model_dkp.eval()\n",
    "    if adversarial == True:\n",
    "        imgs = generate_adversarial(args, model_dkp, imgs, labels)\n",
    "        adv_acc = test_adversarial(model_dkp, imgs, labels)\n",
    "        adv_accuracies.append(adv_acc)\n",
    "    features_dkp = extract_features_dkp(model_dkp, imgs)\n",
    "    _, rdms_dkp = calc_rdms(features_dkp, rdm_method)\n",
    "    models_feats.append(features_dkp)\n",
    "    models_rdms.append(rdms_dkp)\n",
    "    \n",
    "    # ----- DFA -----\n",
    "    # model_dfa.eval()\n",
    "    if adversarial == True:\n",
    "        imgs = generate_adversarial(args, model_dfa, imgs, labels)\n",
    "        adv_acc = test_adversarial(model_dfa, imgs, labels)\n",
    "        adv_accuracies.append(adv_acc)\n",
    "    features_dfa = extract_features_dkp(model_dfa, imgs)\n",
    "    _, rdms_dfa = calc_rdms(features_dfa, rdm_method)\n",
    "    models_feats.append(features_dfa)\n",
    "    models_rdms.append(rdms_dfa)\n",
    "    \n",
    "    return models_rdms, models_feats, adv_accuracies\n",
    "\n",
    "def plot_all_rdms(models_rdms, method_names, n_cols=5, adversarial=False):\n",
    "    \"\"\"\n",
    "    Plots the RDMs of multiple learning rules in a single figure.\n",
    "    Each row corresponds to one learning rule, each row has n_cols RDMs.\n",
    "    Inputs:\n",
    "    - models_rdms (list of dict): List of RDM dictionaries for each method.\n",
    "    - method_names (list of str): Names of learning rules in order.\n",
    "    - n_cols (int): Number of columns/layers per method to display.\n",
    "    \"\"\"\n",
    "    n_methods = len(models_rdms)\n",
    "    fig = plt.figure(figsize=(3*n_cols, 3*n_methods))\n",
    "    gs = fig.add_gridspec(n_methods, n_cols)\n",
    "\n",
    "    for row in range(n_methods):\n",
    "        rdm_dict = models_rdms[row]\n",
    "        layers = list(rdm_dict.keys())[:n_cols]\n",
    "        for col, layer in enumerate(layers):\n",
    "            rdm = np.squeeze(rdm_dict[layer])\n",
    "            if len(rdm.shape) < 2:\n",
    "                size = int(np.sqrt(rdm.shape[0]))\n",
    "                rdm = rdm.reshape((size, size))\n",
    "            rdm = rdm / np.max(rdm)\n",
    "            ax = fig.add_subplot(gs[row, col])\n",
    "            im = ax.imshow(rdm, cmap='magma_r')\n",
    "            if col == 0:\n",
    "                ax.set_ylabel(method_names[row], rotation=0, size='large', labelpad=40, va='center')\n",
    "            ax.set_title(layer)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "    cbar_ax = fig.add_axes([0.92, 0.15, 0.015, 0.7])\n",
    "    fig.colorbar(im, cax=cbar_ax)\n",
    "    cbar_ax.set_ylabel('Normalized euclidean distance', rotation=90, size='medium')\n",
    "    plt.tight_layout(rect=[0, 0, 0.9, 1])\n",
    "    plt.show()\n",
    "    fig.savefig(f\"rdms_all_{args.dataset}{'_adversarial' if adversarial else ''}.png\", dpi=300, bbox_inches='tight')\n",
    "    \n",
    "def rep_path_all(args, model_names, model_colors, imgs, labels=None,\n",
    "                 rdm_calc_method='euclidean', rdm_comp_method='cosine', \n",
    "                 adversarial=False):\n",
    "    \"\"\"\n",
    "    Plots per-method RDM dissimilarity matrices and representational geometry paths,\n",
    "    including optional label representation as the final point in each path.\n",
    "\n",
    "    - models_rdms: list of dicts mapping layer names to raw RDM numpy arrays.\n",
    "    - model_names: list of method names.\n",
    "    - model_colors: dict mapping method names to colors.\n",
    "    - labels: optional tensor of labels for label RDM.\n",
    "    - rdm_calc_method: metric for RDM calculation.\n",
    "    - rdm_comp_method: metric for RDM comparison.\n",
    "    \"\"\"\n",
    "\n",
    "    models_rdms, _, _ = grab_features_and_rdms(args, imgs, labels, rdm_method=rdm_calc_method, adversarial=adversarial)\n",
    "\n",
    "    # Wrap raw RDM matrices into RDMs objects\n",
    "    def wrap_dict(raw_dict):\n",
    "        return {\n",
    "            layer: RDMs(\n",
    "                dissimilarities=np.array([mat]),\n",
    "                dissimilarity_measure=rdm_calc_method,\n",
    "                rdm_descriptors={'layer': [layer]}\n",
    "            )\n",
    "            for layer, mat in raw_dict.items()\n",
    "        }\n",
    "    wrapped_models = [wrap_dict(m) for m in models_rdms]\n",
    "\n",
    "    with plt.xkcd():\n",
    "        fig = plt.figure(figsize=(10, 4 * len(wrapped_models)))\n",
    "        gs = fig.add_gridspec(len(wrapped_models), 2, wspace=0.5, hspace=0.4)\n",
    "\n",
    "        for i, (rdm_dict, method_name) in enumerate(zip(wrapped_models, model_names)):\n",
    "            layers = list(rdm_dict.keys())\n",
    "            rdms = [rdm_dict[layer] for layer in layers]\n",
    "\n",
    "            if labels is not None:\n",
    "                label_rdm, _ = calc_rdms(\n",
    "                    {'labels': F.one_hot(labels).float().to(device)},\n",
    "                    method=rdm_calc_method,\n",
    "                )\n",
    "                label_rdm.dissimilarity_measure = rdm_calc_method  \n",
    "                layers.append('labels')\n",
    "                rdms.append(label_rdm)\n",
    "\n",
    "            # for rdm in rdms:\n",
    "            #     print(rdm.dissimilarity_measure)\n",
    "    \n",
    "            # Concatenate and compare\n",
    "            rdms_concat = rsatoolbox.rdm.concat(*rdms)\n",
    "            comp = rsatoolbox.rdm.compare(rdms_concat, rdms_concat, method=rdm_comp_method)\n",
    "            if rdm_comp_method == 'cosine':\n",
    "                comp = np.arccos(comp)\n",
    "            comp = np.nan_to_num((comp + comp.T) / 2.0)\n",
    "\n",
    "            # Left subplot: dissimilarity matrix\n",
    "            ax0 = fig.add_subplot(gs[i, 0])\n",
    "            im = ax0.imshow(comp, cmap='viridis_r')\n",
    "            fig.colorbar(im, ax=ax0, fraction=0.046, pad=0.04)\n",
    "            ax0.set_title(f'{method_name}: RDM dissimilarity', fontsize=12)\n",
    "            ax0.set_xticks(range(len(layers)))\n",
    "            ax0.set_xticklabels(layers, rotation=80, fontsize=8)\n",
    "            ax0.set_yticks(range(len(layers)))\n",
    "            ax0.set_yticklabels(layers, fontsize=8)\n",
    "\n",
    "            # Right subplot: MDS path\n",
    "            transformer = manifold.MDS(\n",
    "                n_components=2, dissimilarity='precomputed',\n",
    "                max_iter=1000, n_init=10, normalized_stress='auto'\n",
    "            )\n",
    "            coords = transformer.fit_transform(comp)\n",
    "            ax1 = fig.add_subplot(gs[i, 1])\n",
    "            path_end = len(layers) - (1 if labels is not None else 0)\n",
    "            ax1.plot(coords[:path_end, 0], coords[:path_end, 1],\n",
    "                     color=model_colors[method_name], marker='.')\n",
    "            # for idx in range(path_end):\n",
    "            #     ax1.text(coords[idx, 0], coords[idx, 1], layers[idx], fontsize=8)\n",
    "            # Input marker\n",
    "            ax1.plot(coords[0, 0], coords[0, 1], color='k', marker='s')\n",
    "            # Label marker\n",
    "            if labels is not None:\n",
    "                ax1.plot(coords[-1, 0], coords[-1, 1], color='m', marker='*')\n",
    "\n",
    "            ax1.set_title(f'{method_name}: Representational path', fontsize=12)\n",
    "            ax1.set_xlabel('dim 1')\n",
    "            ax1.set_ylabel('dim 2')\n",
    "            lim = coords.max() - coords.min()\n",
    "            ax1.set_xlim(coords[:, 0].min() - 0.1 * lim, coords[:, 0].max() + 0.1 * lim)\n",
    "            ax1.set_ylim(coords[:, 1].min() - 0.1 * lim, coords[:, 1].max() + 0.1 * lim)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        fig.savefig(f\"rep_path_all_{args.dataset}{'_adversarial' if adversarial else ''}.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "def plot_dim_reduction_all(all_model_features, labels, transformer_funcs, method_names=['BP', 'DKP', 'DFA'], adversarial=False):\n",
    "    \"\"\"\n",
    "    Plots dimensionality reduction for multiple methods and layers with a unified class legend.\n",
    "\n",
    "    all_model_features: list of dicts mapping layer names to feature tensors/arrays\n",
    "    labels: 1D array-like of integer labels for samples\n",
    "    transformer_funcs: list of strings specifying transformers (e.g., ['PCA', 't-SNE'])\n",
    "    method_names: list of method names corresponding to all_model_features\n",
    "    \"\"\"\n",
    "    # Prepare transformers\n",
    "    transformers = []\n",
    "    for t in transformer_funcs:\n",
    "        if t == 'PCA':\n",
    "            transformers.append(PCA(n_components=2))\n",
    "        elif t == 'MDS':\n",
    "            transformers.append(manifold.MDS(n_components=2, normalized_stress='auto'))\n",
    "        elif t == 't-SNE':\n",
    "            transformers.append(manifold.TSNE(n_components=2, perplexity=40, verbose=0))\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown transformer: {t}\")\n",
    "\n",
    "    n_methods = len(all_model_features)\n",
    "    n_transformers = len(transformers)\n",
    "    layers = list(all_model_features[0].keys())\n",
    "    n_layers = len(layers)\n",
    "\n",
    "    # Global figure\n",
    "    fig = plt.figure(figsize=(3 * n_layers, 2.5 * n_methods * n_transformers))\n",
    "    gs = fig.add_gridspec(n_methods * n_transformers, n_layers)\n",
    "\n",
    "    # Colors and legend handles\n",
    "    labels_np = np.array(labels)\n",
    "    unique_labels = np.unique(labels_np)\n",
    "    cmap = plt.get_cmap('tab10', len(unique_labels))\n",
    "    norm = mpl.colors.BoundaryNorm(range(len(unique_labels)+1), cmap.N)\n",
    "\n",
    "    # Plot each method/transformer/layer\n",
    "    for m_idx, model_features in enumerate(all_model_features):\n",
    "        for f_idx, transformer in enumerate(transformers):\n",
    "            row_idx = m_idx * n_transformers + f_idx\n",
    "            for l_idx, layer in enumerate(layers):\n",
    "                feats = model_features[layer]\n",
    "                if isinstance(feats, np.ndarray):\n",
    "                    feats = torch.from_numpy(feats)\n",
    "                feats = feats.detach().cpu().flatten(1).numpy()\n",
    "\n",
    "                transformed = transformer.fit_transform(feats)\n",
    "\n",
    "                ax = fig.add_subplot(gs[row_idx, l_idx])\n",
    "                ax.axis('off')\n",
    "                if f_idx == 0:\n",
    "                    ax.set_title(layer, fontsize=12)\n",
    "                if l_idx == 0:\n",
    "                    ax.text(-0.2, 0.5, f\"{method_names[m_idx]}\",\n",
    "                            size=15, ha='right', va='center', transform=ax.transAxes)\n",
    "\n",
    "                sc = ax.scatter(transformed[:, 0], transformed[:, 1], c=labels_np,\n",
    "                                cmap=cmap, norm=norm, s=20)\n",
    "\n",
    "    # Add legend on right side, moved further out to avoid overlap\n",
    "    fig.subplots_adjust(right=0.80, wspace=0.2, hspace=0.2)\n",
    "    # place colorbar further from plots\n",
    "    cax = fig.add_axes([1.05, 0.15, 0.015, 0.7])  # moved left to 0.85, narrower width\n",
    "    cb = mpl.colorbar.ColorbarBase(cax, cmap=cmap, norm=norm,\n",
    "                                    boundaries=np.arange(len(unique_labels)+1)-0.5,\n",
    "                                    ticks=unique_labels, spacing='proportional')\n",
    "    cb.set_label('Class Label')\n",
    "    plt.show()\n",
    "    fig.savefig(f\"tsne_{args.dataset}{'_adversarial' if adversarial else ''}.png\", dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📶 Gradient Signal-to-Noise Ratio (SNR)\n",
    "\n",
    "To assess the quality of learning signals, we compute the SNR of gradients across layers.  \n",
    "A higher SNR indicates more reliable and informative gradient directions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_SNR(args, model, dataset, max_samples=None):\n",
    "    \"\"\"\n",
    "    Computes gradient SNRs for a model given a dataset.\n",
    "    \n",
    "    Arguments:\n",
    "    - model (torch.nn.Module): your CNN (with .list_parameters() and .gather_gradient_dict()).\n",
    "    - dataset (torch.utils.data.Dataset): data to run over.\n",
    "    - max_samples (int or None): if set, stop after this many samples.\n",
    "    \n",
    "    Returns:\n",
    "    - SNR_dict (dict): avg SNR for each parameter name.\n",
    "    \"\"\"\n",
    "    model.to(args.device).eval()\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    # initialize storage for per-sample grads\n",
    "    gradients = {name: [] for name in model.list_parameters()}\n",
    "\n",
    "    for idx, (X, y) in enumerate(loader):\n",
    "        if max_samples is not None and idx >= max_samples:\n",
    "            break\n",
    "\n",
    "        X, y = X.to(args.device), y.to(args.device)\n",
    "        model.zero_grad()\n",
    "\n",
    "        y_pred = model(X)\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        loss.backward()\n",
    "\n",
    "        # collect this sample's grads\n",
    "        for name, grad in model.gather_gradient_dict().items():\n",
    "            if grad is not None:\n",
    "                # detach, move to cpu, flatten into 1D\n",
    "                g = grad.detach().cpu().numpy().ravel()\n",
    "                gradients[name].append(g)\n",
    "\n",
    "    # now compute SNR per parameter\n",
    "    SNR_dict = {}\n",
    "    for name, grad_list in gradients.items():\n",
    "        if len(grad_list) == 0:\n",
    "            SNR_dict[name] = float(\"nan\")\n",
    "            continue\n",
    "        data = np.stack(grad_list, axis=0)   # shape = (n_samples, n_params)\n",
    "        SNR_dict[name] = compute_SNR(data)\n",
    "\n",
    "    return SNR_dict\n",
    "\n",
    "def compute_SNR(data, epsilon=1e-7):\n",
    "    \"\"\"\n",
    "    Calculates the average SNR for of data across the first axis.\n",
    "    \n",
    "    Arguments:\n",
    "    - data (torch Tensor): items x gradients\n",
    "    - epsilon (float, optional): value added to the denominator to avoid\n",
    "      division by zero.\n",
    "    \n",
    "    Returns:\n",
    "    - avg_SNR (float): average SNR across data items\n",
    "    \"\"\"\n",
    "    \n",
    "    absolute_mean = np.abs(np.mean(data, axis=0))\n",
    "    std = np.std(data, axis=0)\n",
    "    SNR_by_item = absolute_mean / (std + epsilon)\n",
    "    avg_SNR = np.mean(SNR_by_item)\n",
    "    \n",
    "    return avg_SNR\n",
    "\n",
    "def plot_gradient_SNRs(SNR_dict, width=0.5, ax=None, adversarial=False):\n",
    "    \"\"\"\n",
    "    Plot gradient SNRs for various learning rules.\n",
    "    \n",
    "    Arguments:\n",
    "    - SNR_dict (dict): Gradient SNRs for each learning rule.\n",
    "    - width (float, optional): Width of the bars.\n",
    "    - ax (plt subplot, optional): Axis on which to plot gradient SNRs. If None, a\n",
    "    new axis will be created.\n",
    "    \n",
    "    Returns:\n",
    "    - ax (plt subplot): Axis on which gradient SNRs were plotted.  \"\"\"\n",
    "    \n",
    "    if ax is None:\n",
    "        wid = min(8, len(SNR_dict) * 1.5)\n",
    "        _, ax = plt.subplots(figsize=(wid, 4))\n",
    "    \n",
    "    xlabels = list()\n",
    "    SNR_means = list()\n",
    "    SNR_sems = list()\n",
    "    SNRs_scatter = list()\n",
    "    for m, (model_type, SNRs) in enumerate(SNR_dict.items()):\n",
    "        xlabels.append(model_type)\n",
    "        color = get_plotting_color(model_idx=m)\n",
    "        ax.bar(\n",
    "            m, np.mean(SNRs), yerr=scipy.stats.sem(SNRs),\n",
    "            alpha=0.5, width=width, capsize=5, color=color\n",
    "            )\n",
    "        s = [20 + i * 30 for i in range(len(SNRs))]\n",
    "        ax.scatter([m] * len(SNRs), SNRs, alpha=0.8, s=s, color=color, zorder=5)\n",
    "    \n",
    "    x = np.arange(len(xlabels))\n",
    "    ax.set_xticks(x)\n",
    "    x_pad = (x.max() - x.min() + width) * 0.3\n",
    "    ax.set_xlim(x.min() - x_pad, x.max() + x_pad)\n",
    "    ax.set_xticklabels(xlabels, rotation=45)\n",
    "    ax.set_xlabel(\"Learning rule\")\n",
    "    ax.set_ylabel(\"SNR\")\n",
    "    ax.set_title(\"SNR of the gradients\")\n",
    "\n",
    "    fig = ax.get_figure()  # Get the figure object from the axes\n",
    "    fig.savefig(f\"snr_{args.dataset}{'_adversarial' if adversarial else ''}.png\", dpi=300, bbox_inches='tight')    \n",
    "    return ax\n",
    "\n",
    "def get_plotting_color(dataset=\"train\", model_idx=None):\n",
    "    if model_idx is not None:\n",
    "        dataset = None\n",
    "    \n",
    "    if model_idx == 0 or dataset == \"train\":\n",
    "        color = \"#1F77B4\" # blue\n",
    "    elif model_idx == 1 or dataset == \"valid\":\n",
    "        color = \"#FF7F0E\" # orange\n",
    "    elif model_idx == 2 or dataset == \"test\":\n",
    "        color = \"#2CA02C\" # green\n",
    "    else:\n",
    "        if model_idx is not None:\n",
    "              raise NotImplementedError(\"Colors only implemented for up to 3 models.\")\n",
    "        else:\n",
    "              raise NotImplementedError(\n",
    "                  f\"{dataset} dataset not recognized. Expected 'train', 'valid' \"\n",
    "                  \"or 'test'.\"\n",
    "                  )\n",
    "    return color\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📐 Cosine Similarity of Gradients\n",
    "\n",
    "We evaluate how closely gradients from DKP and DFA align with those of backpropagation  \n",
    "by measuring cosine similarity over training epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_calculate_cosine_sim(\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    train_mode = 'DKP',\n",
    "    dataset = 'CIFAR10',\n",
    "    num_epochs = 8,\n",
    "    device = \"cuda\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Train both a BP‐trained CNN (model_bp) and a bio-plausible‐trained CNN (dkp, dfa)\n",
    "    for num_epochs, using their respective optimizers & schedulers.  After each\n",
    "    epoch, collect per‐parameter gradients on VALIDATION data (sample‐by‐sample)\n",
    "    and stash them for later cosine‐similarity computation.\n",
    "\n",
    "    Returns:\n",
    "        grads_bp:  dict[param_name] -> list of per‐epoch gradient arrays\n",
    "        grads_lr: dict[param_name] -> list of per‐epoch gradient arrays\n",
    "    \"\"\"\n",
    "    # build_model\n",
    "    if args.dataset == 'CIFAR10':\n",
    "        model_bp = NetCIFAR()\n",
    "        model_lr = ConvNetworkCIFAR(1000, train_mode, device)\n",
    "    elif args.dataset == 'MNIST':\n",
    "        model_bp = NetMNIST()\n",
    "        model_lr = ConvNetworkMNIST(1000, train_mode, device)\n",
    "    \n",
    "    model_bp.to(device).train()\n",
    "    model_lr.to(device).train()\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # optimizer\n",
    "    if train_mode == 'DKP':\n",
    "        test_dkp(model_lr, device, valid_loader, train_loader, None, None, None)\n",
    "\n",
    "        forward_params = []\n",
    "        backward_params = []\n",
    "        for name, param in model_lr.named_parameters():\n",
    "            if \"backward\" in name:\n",
    "                backward_params.append(param)\n",
    "            else:\n",
    "                forward_params.append(param)\n",
    "\n",
    "        forward_optimizer = optim.SGD([{'params': forward_params}], lr=args.lr, weight_decay=1e-6, momentum=0.9, nesterov=True)\n",
    "        backward_optimizer = optim.Adam([{'params': backward_params}], lr=args.b_lr, weight_decay=1e-6)\n",
    "        optimizer_lr = MultipleOptimizer(forward_optimizer, backward_optimizer)\n",
    "        scheduler_lr = StepLR(backward_optimizer, step_size=1, gamma=args.gamma)\n",
    "    elif train_mode == 'DFA':\n",
    "        optimizer_lr = optim.SGD(model_lr.parameters(), lr=args.lr, weight_decay=1e-6, momentum=0.9, nesterov=True)\n",
    "        scheduler_lr = StepLR(optimizer_lr, step_size=1, gamma=args.gamma)\n",
    "\n",
    "    optimizer_bp = optim.Adadelta(model_bp.parameters(), lr=args.bp_lr)\n",
    "    scheduler_bp = StepLR(optimizer_bp, step_size=1, gamma=args.gamma)\n",
    "    \n",
    "    # Prepare storage\n",
    "    cosine_sim_dict = {key: list() for key in model_bp.list_parameters()}\n",
    "    grads_lr = {key: list() for key in cosine_sim_dict.keys()}\n",
    "    grads_bp = {key: list() for key in cosine_sim_dict.keys()}\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # ——— Training Phase ———\n",
    "        # BP model\n",
    "        model_bp.train()\n",
    "        for X, y in train_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            optimizer_bp.zero_grad()\n",
    "            y_pred = model_bp(X)\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer_bp.step()\n",
    "        scheduler_bp.step()\n",
    "\n",
    "        # learning_rule model\n",
    "        model_lr.train()\n",
    "        for X, y in train_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            optimizer_lr.zero_grad()\n",
    "            y_pred = model_lr(X, y)\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer_lr.step()\n",
    "        scheduler_lr.step()\n",
    "\n",
    "        # ——— Validation + Gradient Collection ———\n",
    "        model_bp.eval()\n",
    "        model_lr.eval()\n",
    "        # accumulate per‐sample grads for this epoch\n",
    "        epoch_grads_bp  = {n: [] for n in cosine_sim_dict.keys()}\n",
    "        epoch_grads_lr = {n: [] for n in cosine_sim_dict.keys()}\n",
    "\n",
    "        # But we will turn grad on for loss.backward() below\n",
    "        for X, y in valid_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # BP gradients\n",
    "            model_bp.zero_grad()\n",
    "            y_pred = model_bp(X)\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            for name, grad in model_bp.gather_gradient_dict().items():\n",
    "                epoch_grads_bp[name].append(grad.detach().cpu().ravel().numpy())\n",
    "            model_bp.zero_grad()\n",
    "\n",
    "            # Learning_rule gradients\n",
    "            model_lr.zero_grad()\n",
    "            y_pred = model_lr(X, y)\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            for name, grad in model_lr.gather_gradient_dict().items():\n",
    "                epoch_grads_lr[name].append(grad.detach().cpu().ravel().numpy())\n",
    "            model_lr.zero_grad()\n",
    "\n",
    "        for key in cosine_sim_dict.keys():\n",
    "            lr_grad = np.asarray(epoch_grads_lr[key])  # shape (N, D)\n",
    "            bp_grad = np.asarray(epoch_grads_bp[key])  # shape (N, D)\n",
    "            \n",
    "            if np.allclose(lr_grad, 0):\n",
    "                warnings.warn(\n",
    "                    f\"Learning rule computed all 0 gradients for epoch {epoch}. \"\n",
    "                    \"Cosine similarity cannot be calculated.\"\n",
    "                )\n",
    "                epoch_cosine_sim = np.nan\n",
    "            elif np.allclose(bp_grad, 0):\n",
    "                warnings.warn(\n",
    "                    f\"Backprop. rule computed all 0 gradients for epoch {epoch}. \"\n",
    "                    \"Cosine similarity cannot be calculated.\"\n",
    "                )\n",
    "                epoch_cosine_sim = np.nan\n",
    "            else:\n",
    "                # Normalize each sample's gradient\n",
    "                lr_norm = lr_grad / (np.linalg.norm(lr_grad, axis=1, keepdims=True) + 1e-8)\n",
    "                bp_norm = bp_grad / (np.linalg.norm(bp_grad, axis=1, keepdims=True) + 1e-8)\n",
    "            \n",
    "                # Compute cosine similarity per sample\n",
    "                sample_cosines = np.sum(lr_norm * bp_norm, axis=1)  # shape (N,)\n",
    "            \n",
    "                # Average over all validation samples\n",
    "                epoch_cosine_sim = np.nanmean(sample_cosines)\n",
    "            \n",
    "            cosine_sim_dict[key].append(epoch_cosine_sim)\n",
    "        \n",
    "    return cosine_sim_dict\n",
    "\n",
    "def plot_gradient_cosine_sims(cosine_sim_dict, ax=None):\n",
    "  \"\"\"\n",
    "  Plot gradient cosine similarities to error backpropagation for various\n",
    "  learning rules.\n",
    "\n",
    "  Arguments:\n",
    "  - cosine_sim_dict (dict): Gradient cosine similarities for each learning rule.\n",
    "  - ax (plt subplot, optional): Axis on which to plot gradient cosine\n",
    "    similarities. If None, a new axis will be created.\n",
    "\n",
    "  Returns:\n",
    "  - ax (plt subplot): Axis on which gradient cosine similarities were plotted.\n",
    "  \"\"\"\n",
    "\n",
    "  if ax is None:\n",
    "    _, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "  max_num_epochs = 0\n",
    "  for m, (model_type, cosine_sims) in enumerate(cosine_sim_dict.items()):\n",
    "    cosine_sims = np.asarray(cosine_sims) # params x epochs\n",
    "    num_epochs = cosine_sims.shape[1]\n",
    "    x = np.arange(num_epochs)\n",
    "    cosine_sim_means = np.nanmean(cosine_sims, axis=0)\n",
    "    cosine_sim_sems = scipy.stats.sem(cosine_sims, axis=0, nan_policy=\"omit\")\n",
    "\n",
    "    ax.plot(x, cosine_sim_means, label=model_type, alpha=0.8)\n",
    "\n",
    "    color = get_plotting_color(model_idx=m)\n",
    "    ax.fill_between(\n",
    "        x,\n",
    "        cosine_sim_means - cosine_sim_sems,\n",
    "        cosine_sim_means + cosine_sim_sems,\n",
    "        alpha=0.3, lw=0, color=color\n",
    "        )\n",
    "\n",
    "    for i, param_cosine_sims in enumerate(cosine_sims):\n",
    "      s = 20 + i * 30\n",
    "      ax.scatter(x, param_cosine_sims, color=color, s=s, alpha=0.6)\n",
    "\n",
    "    max_num_epochs = max(max_num_epochs, num_epochs)\n",
    "\n",
    "  if max_num_epochs > 0:\n",
    "    x = np.arange(max_num_epochs)\n",
    "    xlabels = [f\"{int(e)}\" for e in x]\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(xlabels)\n",
    "\n",
    "  ymin = ax.get_ylim()[0]\n",
    "  ymin = min(-0.1, ymin)\n",
    "  ax.set_ylim(ymin, 1.1)\n",
    "\n",
    "  ax.axhline(0, ls=\"dashed\", color=\"k\", zorder=-5, alpha=0.5)\n",
    "\n",
    "  ax.set_xlabel(\"Epoch\")\n",
    "  ax.set_ylabel(\"Cosine similarity\")\n",
    "  ax.set_title(\"Cosine similarity to backprop gradients\")\n",
    "  ax.legend()\n",
    "\n",
    "  return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🏗️ Model Architecture: ConvNetBP\n",
    "\n",
    "A standard CNN with ReLU, batch normalization, and max pooling.  \n",
    "Used for training with backpropagation.  \n",
    "Includes hooks for collecting gradients during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNetBP(nn.Module):\n",
    "    def __init__(self, in_channels, input_size):\n",
    "        super(ConvNetBP, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, 1)\n",
    "        self.conv1_bn = nn.BatchNorm2d(32)\n",
    "        self.conv2_bn = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Determine size after conv and pooling\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, in_channels, input_size, input_size)\n",
    "            x = self.conv1(dummy)\n",
    "            x = self.conv1_bn(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.conv2(x)\n",
    "            x = self.conv2_bn(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.max_pool2d(x, 2)\n",
    "            n_features = x.shape[1] * x.shape[2] * x.shape[3]\n",
    "\n",
    "        self.fc1 = nn.Linear(n_features, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.conv1(input)\n",
    "        x = self.conv1_bn(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv2_bn(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def list_parameters(self):\n",
    "        \"\"\"\n",
    "        Returns a list of model names for a gradient dictionary.\n",
    "        \n",
    "        Returns:\n",
    "        - params_list (list): List of parameter names.\n",
    "        \"\"\"\n",
    "        \n",
    "        params_list = list()\n",
    "        \n",
    "        for layer_str in [\"conv1\", \"conv2\", \"fc1\", \"fc2\"]:\n",
    "          params_list.append(f\"{layer_str}_weight\")\n",
    "          # if self.bias:\n",
    "          #   params_list.append(f\"{layer_str}_bias\")\n",
    "        \n",
    "        return params_list\n",
    "    \n",
    "    def gather_gradient_dict(self):\n",
    "        \"\"\"\n",
    "        Gathers a gradient dictionary for the model's parameters. Raises a\n",
    "        runtime error if any parameters have no gradients.\n",
    "        \n",
    "        Returns:\n",
    "        - gradient_dict (dict): A dictionary of gradients for each parameter.\n",
    "        \"\"\"\n",
    "        \n",
    "        params_list = self.list_parameters()\n",
    "        \n",
    "        gradient_dict = dict()\n",
    "        for param_name in params_list:\n",
    "          layer_str, param_str = param_name.split(\"_\")\n",
    "          layer = getattr(self, layer_str)\n",
    "          grad = getattr(layer, param_str).grad\n",
    "          if grad is None:\n",
    "            raise RuntimeError(\"No gradient was computed\")\n",
    "          gradient_dict[param_name] = grad.detach().clone() \n",
    "\n",
    "        return gradient_dict\n",
    "\n",
    "def train_bp(args, model, device, train_loader, optimizer, epoch, batch_size, writer):\n",
    "    model.train()\n",
    "\n",
    "    training_loss = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.4f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "            if args.dry_run:\n",
    "                break\n",
    "\n",
    "        training_loss += loss\n",
    "\n",
    "    training_loss /= (batch_idx + 1)\n",
    "\n",
    "    writer.add_scalar('loss/training_loss', training_loss.item(), epoch)\n",
    "\n",
    "    writer.close()\n",
    "    return training_loss.item()\n",
    "\n",
    "def test_bp(model, device, test_loader, train_loader, epoch, batch_size, writer):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= (batch_idx + 1)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: ({:.2f}%)\\n'.format(\n",
    "        test_loss, test_accuracy))\n",
    "\n",
    "    if epoch is not None:\n",
    "        writer.add_scalar('loss/test_loss', test_loss, epoch)\n",
    "        writer.add_scalar('accuracy/test_accuracy', test_accuracy, epoch)\n",
    "        writer.close()\n",
    "\n",
    "    return test_loss, test_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🏗️ Model Architecture: ConvNetDKP / DFA\n",
    "\n",
    "A CNN model modified to support biologically plausible learning.  \n",
    "Backward weights are either learned (DKP) or fixed random (DFA).  \n",
    "Includes gradient injection and alignment diagnostics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleOptimizer(object):\n",
    "    def __init__(self, *op):\n",
    "        self.optimizers = op\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for op in self.optimizers:\n",
    "            op.zero_grad()\n",
    "\n",
    "    def step(self):\n",
    "        for op in self.optimizers:\n",
    "            op.step()\n",
    "\n",
    "    def state_dict(self):\n",
    "        for op in self.optimizers:\n",
    "            op.state_dict()\n",
    "\n",
    "class OutputTrainingHook(nn.Module):\n",
    "    #This training hook captures and handles the gradients at the output of the network\n",
    "    def __init__(self):\n",
    "        super(OutputTrainingHook, self).__init__()\n",
    "\n",
    "    def forward(self, input, grad_at_output):\n",
    "        return OutputHookFunction.apply(input, grad_at_output)\n",
    "\n",
    "class OutputHookFunction(autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, grad_at_output):\n",
    "        ctx.save_for_backward(input)\n",
    "        ctx.in1 = grad_at_output\n",
    "        return input\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        grad_at_output = ctx.in1\n",
    "        input = ctx.saved_variables\n",
    "\n",
    "        grad_at_output[:grad_output.shape[0], :].data.copy_(grad_output.data)\n",
    "\n",
    "        return grad_output, None\n",
    "\n",
    "class DFATrainingHook(nn.Module):\n",
    "    #This training hook calculates and injects the gradients made by DFA\n",
    "    def __init__(self, train_mode):\n",
    "        super(DFATrainingHook, self).__init__()\n",
    "        self.train_mode = train_mode\n",
    "        self.is_not_initialized = True\n",
    "        self.backward_weights = nn.Parameter(requires_grad=True)\n",
    "\n",
    "    def init_weights(self, dim, device):\n",
    "        self.backward_weights = nn.Parameter(torch.Tensor(torch.Size(dim)).to(device))\n",
    "        if self.train_mode == 'DKP':\n",
    "            self.backward_weights.requires_grad = True\n",
    "            torch.nn.init.kaiming_uniform_(self.backward_weights)\n",
    "            # torch.nn.init.zeros_(self.backward_weights)\n",
    "        elif self.train_mode == 'DFA':\n",
    "            self.backward_weights.requires_grad = False\n",
    "            torch.nn.init.kaiming_uniform_(self.backward_weights)\n",
    "\n",
    "    def forward(self, input, grad_at_output, network_output):\n",
    "        if self.is_not_initialized and self.train_mode in ['DKP', 'DFA']:\n",
    "            if len(input.shape) > 2:\n",
    "                dim = [grad_at_output.shape[1], input.shape[1], input.shape[2], input.shape[3]]\n",
    "            else:\n",
    "                dim = [grad_at_output.shape[1], input.shape[1]]\n",
    "            self.init_weights(dim, input.device)\n",
    "            self.is_not_initialized = False\n",
    "\n",
    "        return DFAHookFunction.apply(input, self.backward_weights, grad_at_output, network_output, self.train_mode)\n",
    "\n",
    "class DFAHookFunction(autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, backward_weights, grad_at_output, network_output, train_mode):\n",
    "        ctx.save_for_backward(input, backward_weights)\n",
    "        ctx.in1 = grad_at_output\n",
    "        ctx.in2 = network_output\n",
    "        ctx.in3 = train_mode\n",
    "        return input\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        grad_at_output            = ctx.in1\n",
    "        network_output            = ctx.in2\n",
    "        train_mode                = ctx.in3\n",
    "        input, backward_weights   = ctx.saved_variables\n",
    "\n",
    "        grad_at_output = grad_at_output[:grad_output.shape[0], :]\n",
    "        network_output = network_output[:grad_output.shape[0], :]\n",
    "\n",
    "        if train_mode == 'DFA':\n",
    "            B_view = backward_weights.view(-1, prod(backward_weights.shape[1:]))\n",
    "            grad_output_est = grad_at_output.mm(B_view).view(grad_output.shape)\n",
    "            return grad_output_est, None, None, None, None\n",
    "\n",
    "        elif train_mode == 'DKP':\n",
    "            layer_out_view = input.view(-1, prod(input.shape[1:]))\n",
    "            B_view = backward_weights.view(-1, prod(backward_weights.shape[1:]))\n",
    "\n",
    "            grad_output_est = grad_at_output.mm(B_view)\n",
    "            grad_weights_B = grad_at_output.t().mm(layer_out_view)\n",
    "\n",
    "            return grad_output_est.view(grad_output.shape), grad_weights_B.view(backward_weights.shape), None, None, None\n",
    "\n",
    "        return grad_output, None, None, None\n",
    "\n",
    "class ConvNetDKP(nn.Module):\n",
    "    def __init__(self, args, in_channels, input_size):\n",
    "        super(ConvNetDKP, self).__init__()\n",
    "        self.batch_size = args.batch_size\n",
    "        self.train_mode = args.train_mode\n",
    "        self.device = args.device\n",
    "\n",
    "        # Initialize hooks and layers\n",
    "        self.conv1 = nn.Conv2d(in_channels, 32, 3, 1)\n",
    "        self.conv1_bn = nn.BatchNorm2d(32)\n",
    "        self.conv1_dfa = DFATrainingHook(self.train_mode)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, 1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(32)\n",
    "        self.conv2_dfa = DFATrainingHook(self.train_mode)\n",
    "\n",
    "        # 1) CPU shape inference\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, in_channels, input_size, input_size)  # CPU tensor\n",
    "            x = self.conv1(dummy)\n",
    "            x = self.conv1_bn(x)\n",
    "            x = F.relu(x)\n",
    "            self._conv1_shape = list(x.shape[1:])  # Save conv1 output shape\n",
    "\n",
    "            x = self.conv2(x)\n",
    "            x = self.conv2_bn(x)\n",
    "            x = F.relu(x)\n",
    "            self._conv2_shape = list(x.shape[1:])  # Save conv2 output shape\n",
    "\n",
    "            x = F.max_pool2d(x, 2)\n",
    "            flatten_dim = x.numel() // x.shape[0]\n",
    "\n",
    "        # Define fully connected layers\n",
    "        self.fc1 = nn.Linear(flatten_dim, 128)\n",
    "        self.fc1_dfa = DFATrainingHook(self.train_mode)\n",
    "\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.output_hook = OutputTrainingHook()\n",
    "\n",
    "        # 2) Move model to target device\n",
    "        self.to(self.device)\n",
    "\n",
    "        # 3) Allocate buffers directly on the correct device using cached shapes\n",
    "        self.grad_at_output = torch.zeros(self.batch_size, 10, device=self.device)\n",
    "        self.network_output = torch.zeros(self.batch_size, 10, device=self.device)\n",
    "\n",
    "        self.conv1_out = torch.zeros([self.batch_size] + self._conv1_shape, requires_grad=False, device=self.device)\n",
    "        self.conv2_out = torch.zeros([self.batch_size] + self._conv2_shape, requires_grad=False, device=self.device)\n",
    "        self.fc1_out = torch.zeros(self.batch_size, 128, requires_grad=False, device=self.device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "    \n",
    "        # Dynamically reallocate tensors if batch size has changed\n",
    "        if self.grad_at_output.shape[0] != batch_size:\n",
    "            self.grad_at_output = torch.zeros(batch_size, 10, device=x.device)\n",
    "            self.network_output = torch.zeros(batch_size, 10, device=x.device)\n",
    "            self.conv1_out = torch.zeros([batch_size] + self._conv1_shape, device=x.device)\n",
    "            self.conv2_out = torch.zeros([batch_size] + self._conv2_shape, device=x.device)\n",
    "            self.fc1_out = torch.zeros(batch_size, 128, device=x.device)\n",
    "    \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv1_bn(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv1_dfa(x, self.grad_at_output, self.network_output)\n",
    "        if x.requires_grad:\n",
    "            self.conv1_out[:batch_size].data.copy_(x.data)\n",
    "    \n",
    "        x = self.conv2(x)\n",
    "        x = self.conv2_bn(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2_dfa(x, self.grad_at_output, self.network_output)\n",
    "        if x.requires_grad:\n",
    "            self.conv2_out[:batch_size].data.copy_(x.data)\n",
    "    \n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = torch.flatten(x, 1)\n",
    "    \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc1_dfa(x, self.grad_at_output, self.network_output)\n",
    "        if x.requires_grad:\n",
    "            self.fc1_out[:batch_size].data.copy_(x.data)\n",
    "    \n",
    "        x = self.fc2(x)\n",
    "    \n",
    "        if x.requires_grad:\n",
    "            x = self.output_hook(x, self.grad_at_output)\n",
    "            self.network_output[:batch_size].data.copy_(x.data)\n",
    "    \n",
    "        return x\n",
    "\n",
    "    def list_parameters(self):\n",
    "\n",
    "        params_list = list()\n",
    "        \n",
    "        for layer_str in [\"conv1\", \"conv2\", \"fc1\", \"fc2\"]:\n",
    "          params_list.append(f\"{layer_str}_weight\")\n",
    "          # if self.bias:\n",
    "          #   params_list.append(f\"{layer_str}_bias\")\n",
    "        \n",
    "        return params_list\n",
    "    \n",
    "    def gather_gradient_dict(self):\n",
    "        \n",
    "        params_list = self.list_parameters()\n",
    "        \n",
    "        gradient_dict = dict()\n",
    "        for param_name in params_list:\n",
    "          layer_str, param_str = param_name.split(\"_\")\n",
    "          layer = getattr(self, layer_str)\n",
    "          grad = getattr(layer, param_str).grad\n",
    "          if grad is None:\n",
    "            raise RuntimeError(\"No gradient was computed\")\n",
    "          gradient_dict[param_name] = grad.detach().clone() \n",
    "\n",
    "        return gradient_dict\n",
    "\n",
    "def train_dkp(args, model, device, train_loader, optimizer, epoch, batch_size, writer):\n",
    "    model.train()\n",
    "\n",
    "    training_loss = 0\n",
    "    alignment_fc1 = 0\n",
    "    alignment_conv1 = 0\n",
    "    alignment_conv2 = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "\n",
    "        align_fc1 = torch.mean(F.cosine_similarity(\n",
    "            output.detach(),\n",
    "            model.fc1_out[:output.shape[0], :].mm(model.fc1_dfa.backward_weights.t())\n",
    "        ))\n",
    "        align_conv1 = torch.mean(F.cosine_similarity(\n",
    "            output.detach(),\n",
    "            model.conv1_out[:output.shape[0]].view(output.shape[0], -1).mm(\n",
    "                model.conv1_dfa.backward_weights.view(model.conv1_dfa.backward_weights.shape[0], -1).t()\n",
    "            )\n",
    "        ))\n",
    "        align_conv2 = torch.mean(F.cosine_similarity(\n",
    "            output.detach(),\n",
    "            model.conv2_out[:output.shape[0]].view(output.shape[0], -1).mm(\n",
    "                model.conv2_dfa.backward_weights.view(model.conv2_dfa.backward_weights.shape[0], -1).t()\n",
    "            )\n",
    "        ))\n",
    "\n",
    "        alignment_fc1 += align_fc1.item()\n",
    "        alignment_conv1 += align_conv1.item()\n",
    "        alignment_conv2 += align_conv2.item()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.4f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "            if args.dry_run:\n",
    "                break\n",
    "\n",
    "        training_loss += loss\n",
    "\n",
    "    training_loss /= (batch_idx + 1)\n",
    "\n",
    "    writer.add_scalar('loss/training_loss', training_loss.item(), epoch)\n",
    "    writer.add_scalar('cos_alignment/fc1_to_output', alignment_fc1 / (batch_idx + 1), epoch)\n",
    "    writer.add_scalar('cos_alignment/conv1_to_output', alignment_conv1 / (batch_idx + 1), epoch)\n",
    "    writer.add_scalar('cos_alignment/conv2_to_output', alignment_conv2 / (batch_idx + 1), epoch)\n",
    "\n",
    "    writer.close()\n",
    "    return training_loss.item()\n",
    "\n",
    "def test_dkp(model, device, test_loader, train_loader, epoch, batch_size, writer):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= (batch_idx + 1)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: ({:.2f}%)\\n'.format(\n",
    "        test_loss, test_accuracy))\n",
    "\n",
    "    if epoch is not None:\n",
    "        writer.add_scalar('loss/test_loss', test_loss, epoch)\n",
    "        writer.add_scalar('accuracy/test_accuracy', test_accuracy, epoch)\n",
    "        writer.close()\n",
    "\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🏃‍♂️ Training Loop: Backpropagation\n",
    "\n",
    "The training function for the BP model.  \n",
    "Tracks loss and accuracy over epochs, and saves CSV logs and checkpoints.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sx0-B0ZciOUg"
   },
   "outputs": [],
   "source": [
    "def main_bp(args):\n",
    "\n",
    "    train_loader, test_loader = fetch_dataloaders(args)\n",
    "\n",
    "    images, labels = next(iter(train_loader)) \n",
    "    in_channels = images.shape[1]\n",
    "    input_height = images.shape[2]\n",
    "\n",
    "    model = ConvNetBP(in_channels, input_height).to(args.device)\n",
    "\n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=args.bp_lr)\n",
    "\n",
    "    writer = SummaryWriter(log_dir='results/conv_bp')\n",
    "    logger = CSVLogger(['Epoch', 'Training Loss', 'Test Loss', 'Test Accuracy'], args)\n",
    "\n",
    "    # optimizer = optim.SGD(model.parameters(), lr=args.lr, weight_decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
    "\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        training_loss = train_bp(args, model, device, train_loader, optimizer, epoch, args.batch_size, writer)\n",
    "        test_loss, test_accuracy = test_bp(model, device, test_loader, train_loader, epoch, args.batch_size, writer)\n",
    "        logger.save_values(epoch, training_loss, test_loss, test_accuracy)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    if args.save_model:\n",
    "        torch.save(model.state_dict(), f\"model_checkpoints/BP_{args.dataset}_epoch{args.epochs}_s{args.seed}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4WOPms9ju03W"
   },
   "outputs": [],
   "source": [
    "# train BP on CIFAR10 and save results on CSV and save model params\n",
    "\n",
    "# args.train_mode = 'BP'\n",
    "# args.dataset = 'CIFAR10'\n",
    "\n",
    "# main_bp(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L17KCeWlu03W"
   },
   "outputs": [],
   "source": [
    "# train BP on MNIST and save results on CSV and save model params\n",
    "\n",
    "# args.train_mode = 'BP'\n",
    "# args.dataset = 'MNIST'\n",
    "\n",
    "# main_bp(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🏃‍♂️ Training Loop: DKP / DFA\n",
    "\n",
    "Shared training loop for DKP and DFA models.  \n",
    "Includes:\n",
    "- Weight separation (forward vs backward)\n",
    "- Hook registration\n",
    "- Cosine similarity diagnostics\n",
    "- TensorBoard logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NNBVKOnbmYOP"
   },
   "outputs": [],
   "source": [
    "def main_dkp(args):\n",
    "\n",
    "    train_loader, test_loader = fetch_dataloaders(args)\n",
    "\n",
    "    images, labels = next(iter(train_loader)) \n",
    "    in_channels = images.shape[1]\n",
    "    input_height = images.shape[2]\n",
    "    \n",
    "    model = ConvNetDKP(args, in_channels, input_height).to(args.device)\n",
    "\n",
    "    writer = SummaryWriter(log_dir='results/conv_dkp')\n",
    "    logger = CSVLogger(['Epoch', 'Training Loss', 'Test Loss', 'Test Accuracy'], args)\n",
    "\n",
    "    if args.train_mode == 'DKP':\n",
    "        test_dkp(model, args.device, test_loader, train_loader, None, None, None)\n",
    "\n",
    "        forward_params = []\n",
    "        backward_params = []\n",
    "        for name, param in model.named_parameters():\n",
    "            if \"backward\" in name:\n",
    "                backward_params.append(param)\n",
    "            else:\n",
    "                forward_params.append(param)\n",
    "\n",
    "        forward_optimizer = optim.SGD([{'params': forward_params}], lr=args.lr, weight_decay=1e-6, momentum=0.9, nesterov=True)\n",
    "        backward_optimizer = optim.Adam([{'params': backward_params}], lr=args.b_lr, weight_decay=1e-6)\n",
    "        optimizer = MultipleOptimizer(forward_optimizer, backward_optimizer)\n",
    "        scheduler = StepLR(backward_optimizer, step_size=1, gamma=args.gamma)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=args.lr, weight_decay=1e-6, momentum=0.9, nesterov=True)\n",
    "        scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
    "\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        training_loss = train_dkp(args, model, args.device, train_loader, optimizer, epoch, args.batch_size, writer)\n",
    "        test_loss, test_accuracy = test_dkp(model, args.device, test_loader, train_loader, epoch, args.batch_size, writer)\n",
    "        logger.save_values(epoch, training_loss, test_loss, test_accuracy)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    if args.save_model:\n",
    "        torch.save(model.state_dict(), f\"model_checkpoints/{args.train_mode}_{args.dataset}_epoch{args.epochs}_s{args.seed}.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vifbXGaBu03X"
   },
   "outputs": [],
   "source": [
    "# train DKP on CIFAR10 and save results on CSV and save model params\n",
    "\n",
    "# args.train_mode = 'DKP'\n",
    "# args.dataset = 'CIFAR10'\n",
    "\n",
    "# main_dkp(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kTuG2Ghsu03X"
   },
   "outputs": [],
   "source": [
    "# train DKP on MNIST and save results on CSV and save model params\n",
    "\n",
    "# args.train_mode = 'DKP'\n",
    "# args.dataset = 'MNIST'\n",
    "\n",
    "# main_dkp(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yzWybElhu03X"
   },
   "outputs": [],
   "source": [
    "# train DFA on CIFAR10 and save results on CSV and save model params\n",
    "\n",
    "# args.train_mode = 'DFA'\n",
    "# args.dataset = 'CIFAR10'\n",
    "\n",
    "# main_dkp(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KOO354Vsu03X"
   },
   "outputs": [],
   "source": [
    "# train DFA on MNIST and save results on CSV and save model params\n",
    "\n",
    "# args.train_mode = 'DFA'\n",
    "# args.dataset = 'MNIST'\n",
    "\n",
    "# main_dkp(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧪 Evaluation on CIFAR-10\n",
    "\n",
    "This section includes full evaluation pipeline for CIFAR-10:\n",
    "- RDM visualization\n",
    "- MDS (representation trajectory)\n",
    "- Adversarial robustness using FGSM\n",
    "- Accuracy under adversarial attack\n",
    "- Feature space visualization using t-SNE\n",
    "- SNR computation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.dataset = 'CIFAR10'\n",
    "train_loader, test_loader = fetch_dataloaders(args)\n",
    "imgs, labels = sample_images_cifar(test_loader, n=20)\n",
    "models_rdms, _, _ = grab_features_and_rdms(args, imgs, labels)\n",
    "plot_all_rdms(models_rdms, method_names, n_cols=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs, labels = sample_images_cifar(test_loader, n=20)\n",
    "imgs, labels = next(iter(test_loader))\n",
    "rep_path_all(args, method_names, model_colors, imgs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = sample_images_cifar(test_loader, n=20)\n",
    "models_rdms, _, adv_accuracies = grab_features_and_rdms(args, imgs, labels, adversarial=True)\n",
    "plot_all_rdms(models_rdms, method_names, n_cols=5, adversarial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, acc in enumerate(adv_accuracies):\n",
    "    print(f\"Model: {method_names[i]} | Accuracy: {100 * acc :.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = sample_images_cifar(test_loader, n=50)\n",
    "_, models_feats, _ = grab_features_and_rdms(args, imgs, labels)\n",
    "plot_dim_reduction_all(models_feats, labels, transformer_funcs=['t-SNE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = sample_images_cifar(test_loader, n=10)\n",
    "SNR_dict = dict()\n",
    "models_dict = load_models(args, imgs)\n",
    "\n",
    "for name, model in models_dict.items():\n",
    "    model_SNR_dict = compute_gradient_SNR(args, model, test_loader.dataset, max_samples=1000)\n",
    "    SNR_dict[name] = [SNR for SNR in model_SNR_dict.values()]\n",
    "\n",
    "plot_gradient_SNRs(SNR_dict);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧪 Evaluation on MNIST\n",
    "\n",
    "We replicate the CIFAR-10 analysis on MNIST:\n",
    "- Internal representation comparison\n",
    "- Adversarial image generation and testing\n",
    "- Feature visualization via t-SNE\n",
    "- Gradient SNR for BP, DKP, DFA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.dataset = 'MNIST'\n",
    "train_loader, test_loader = fetch_dataloaders(args)\n",
    "imgs, labels = sample_images_mnist(test_loader, n=20)\n",
    "models_rdms, _, _ = grab_features_and_rdms(args, imgs, labels)\n",
    "plot_all_rdms(models_rdms, method_names, n_cols=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs, labels = sample_images_mnist(test_loader, n=20)\n",
    "imgs, labels = next(iter(test_loader))\n",
    "rep_path_all(args, method_names, model_colors, imgs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = sample_images_mnist(test_loader, n=20)\n",
    "models_rdms, _, adv_accuracies = grab_features_and_rdms(args, imgs, labels, adversarial=True)\n",
    "plot_all_rdms(models_rdms, method_names, n_cols=5, adversarial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, acc in enumerate(adv_accuracies):\n",
    "    print(f\"Model: {method_names[i]} | Accuracy: {100 * acc :.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = sample_images_mnist(test_loader, n=50)\n",
    "_, models_feats, _ = grab_features_and_rdms(args, imgs, labels)\n",
    "plot_dim_reduction_all(models_feats, labels, transformer_funcs=['t-SNE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = sample_images_mnist(test_loader, n=10)\n",
    "SNR_dict = dict()\n",
    "models_dict = load_models(args, imgs)\n",
    "\n",
    "for name, model in models_dict.items():\n",
    "    model_SNR_dict = compute_gradient_SNR(args, model, test_loader.dataset, max_samples=1000)\n",
    "    SNR_dict[name] = [SNR for SNR in model_SNR_dict.values()]\n",
    "\n",
    "plot_gradient_SNRs(SNR_dict);"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "z89avT5sdJUC",
    "ilLikLlxc91a"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
